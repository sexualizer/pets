# pets
ETL pipeline which include some operations on data about houses in Russia and their loading in PSQL DB using Airflow DAG

Contains: 
1. Dockerfile to use PySpark
2. Docker-compose based on Dockerfile to run whole app
3. Requirements.txt to use Python libs which will be ran in yaml file
4. DAG is stored in airflow folder as houses.py
